{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPXDhbaUq1dL"
      },
      "outputs": [],
      "source": [
        "# Importazione delle librerie necessarie\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caricamento del dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()\n",
        "\n",
        "# Unisci tutto in un unico dataset\n",
        "X = np.concatenate((x_train_flat, x_test_flat), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Concatenazione dati e target\n",
        "daticompleti = np.c[X, y]\n",
        "\n",
        "# Split settings\n",
        "train_fraction = 0.8\n",
        "val_fraction = 0.25\n",
        "\n",
        "shape_total = dati_completi.shape[0]\n",
        "shape_train = int(shape_total * train_fraction)\n",
        "shape_val = int(shape_train * val_fraction)\n",
        "\n",
        "# Split dataset\n",
        "train_set = dati_completi[:shape_train]\n",
        "test_set = dati_completi[shape_train:]\n",
        "\n",
        "val_set = train_set[:shape_val]\n",
        "train_effettivo_set = train_set[shape_val:]\n",
        "\n",
        "x_train_eff, y_train_eff = train_effettivo_set[:, :-1], train_effettivo_set[:, -1]\n",
        "x_val, y_val = val_set[:, :-1], val_set[:, -1]\n",
        "x_test, y_test = test_set[:, :-1], test_set[:, -1]\n",
        "\n",
        "#standardizzazione\n",
        "scaler = StandardScaler()\n",
        "x_train_std = scaler.fit_transform(x_train_eff)\n",
        "x_test_std = scaler.transform(x_test)\n",
        "\n",
        "\n",
        "# Appiattimento immagini da (32, 32, 3) a (3072,)\n",
        "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "X_test_flat = X_test.reshape((X_test.shape[0], -1))\n",
        "\n",
        "\n",
        "# sottocampionamento (opzionale)\n",
        "sample_size = 10000\n",
        "X_train = X_train[:sample_size]\n",
        "y_train = y_train[:sample_size]\n",
        "\n",
        "\n",
        "# Standardizzazione delle feature\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled = scaler.transform(X_test_flat)"
      ],
      "metadata": {
        "id": "n18yD2R8rO0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applica PCA per ridurre dimensionalit√† da 3072 a 100\n",
        "pca = PCA(n_components=100)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "explained = np.sum(pca.explained_variance_ratio_)\n",
        "print(f\"PCA con 100 componenti spiega il {explained:.2%} della varianza totale\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAGbIWjM5h2R",
        "outputId": "b1850b04-83d4-47a3-f73f-31730a0c248d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA con 100 componenti spiega il 89.83% della varianza totale\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importazione librerie necessarie per l'addestramento dei modelli (regressione logistica, k-NN, SVM, decision tree)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "hkEEZqG460BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creiamo una lista per raccogliere i risultati\n",
        "\n",
        "risultati = {}\n",
        "\n",
        "# allenamento modello di regressione logistica\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train_pca, y_train)\n",
        "y_pred_lr = logreg.predict(X_test_pca)\n",
        "risultati['Logistic Regression'] = accuracy_score(y_test, y_pred_lr)\n",
        "\n",
        "# allenamento modello K-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_pca, y_train)\n",
        "y_pred_knn = knn.predict(X_test_pca)\n",
        "risultati['k-NN'] = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "# allenamento modello SVM\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train_pca, y_train)\n",
        "y_pred_svm = svm.predict(X_test_pca)\n",
        "risultati['SVM'] = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "# allenamento modello decision tree\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(X_train_pca, y_train)\n",
        "y_pred_dt = tree.predict(X_test_pca)\n",
        "risultati['Decision Tree'] = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "# Stampiamo i risultati\n",
        "for model_name, acc in risultati.items():\n",
        "    print(f\"{model_name} - Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "zYKO4Zu7-a35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importazione della libreria per implementare GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "eNRUXBdKHbLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Logistic Regression\n",
        "param_logreg = {\n",
        "    'C': [0.01, 0.1, 1, 10]\n",
        "}\n",
        "grid_logreg = GridSearchCV(LogisticRegression(max_iter=1000), param_logreg, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_logreg.fit(X_train_pca, y_train)\n",
        "best_logreg = grid_logreg.best_estimator_\n",
        "\n",
        "# 2. k-NN\n",
        "param_knn = {\n",
        "    'n_neighbors': [3, 5, 7]\n",
        "}\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_knn, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_knn.fit(X_train_pca, y_train)\n",
        "best_knn = grid_knn.best_estimator_\n",
        "\n",
        "# 3. SVM\n",
        "param_svm = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 0.01, 0.001],\n",
        "    'kernel': ['linear', 'rbf']\n",
        "}\n",
        "grid_svm = GridSearchCV(SVC(), param_svm, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_svm.fit(X_train_pca, y_train)\n",
        "best_svm = grid_svm.best_estimator_\n",
        "\n",
        "# 4. Decision Tree\n",
        "param_tree = {\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "grid_tree = GridSearchCV(DecisionTreeClassifier(), param_tree, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_tree.fit(X_train_pca, y_train)\n",
        "best_tree = grid_tree.best_estimator_"
      ],
      "metadata": {
        "id": "0wtTqWb2Hn6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Logistic Regression': best_logreg,\n",
        "    'k-NN': best_knn,\n",
        "    'SVM': best_svm,\n",
        "    'Decision Tree': best_tree\n",
        "}\n",
        "\n",
        "for i, (name, model) in enumerate(models.items(), 1):\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\n{name} - Accuracy: {acc:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Calcolo e visualizzazione della confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Visualizzazione della confusion matrix\n",
        "    plt.subplot(1, 2, i)\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.title(f'Confusion Matrix: {name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IGr_vB0vL0iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#scelta del modello dalle migliori prestazioni\n",
        "\n",
        "best_lr_acc = accuracy_score(y_test, grid_lr.predict(x_test_pca))\n",
        "best_knn_acc = accuracy_score(y_test, grid_knn.predict(x_test_pca))\n",
        "best_svm_acc = accuracy_score(y_test, grid_svm.predict(x_test_pca))\n",
        "best_dt_acc = accuracy_score(y_test, grid_dt.predict(x_test_pca))\n",
        "\n",
        "\n",
        "accuracies = [best_lr_acc, best_knn_acc, best_svm_acc, best_dt_acc]\n",
        "model_names = [\"Logistic Regression\", \"k-NN\", \"SVM\", \"Decision Tree\"]\n",
        "best_index = accuracies.index(max(accuracies))\n",
        "best_model_name = model_names[best_index]\n",
        "print(f\" Modello migliore: {best_model_name} (accuracy: {accuracies[best_index]:.4f})\")\n",
        "\n",
        "\n",
        "\n",
        "#visualizzazione della relativa confusion matrix\n",
        "best_model = [best_lr, best_knn, best_svm, best_dt][best_index]\n",
        "y_pred = best_model.predict(x_test_pca)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plot_confusion_matrix(cm)"
      ],
      "metadata": {
        "id": "4xpe5ebXWiUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "clysUUFwQbv1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}